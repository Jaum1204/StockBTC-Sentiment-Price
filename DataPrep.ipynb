{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "import nltk\n",
    "import spacy\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "\n",
    "import en_core_web_md\n",
    "text_to_nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "INVISIBLE_CHARS = re.compile(r'[\\u200B\\u200C\\u200D\\u200E\\u200F\\uFEFF\\u00A0]')\n",
    "URLS = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "EMOJIS = re.compile(\"[\"\n",
    "                    u\"\\U0001F600-\\U0001F64F\"\n",
    "                    u\"\\U0001F300-\\U0001F5FF\"\n",
    "                    u\"\\U0001F680-\\U0001F6FF\"\n",
    "                    u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                    u\"\\U00002700-\\U000027BF\"\n",
    "                    u\"\\U000024C2-\\U0001F251\"\n",
    "                    \"]+\", flags=re.UNICODE)\n",
    "\n",
    "REMOVE_PUNCT_DIGITS = str.maketrans('', '', string.punctuation + string.digits)\n",
    "CUSTOM_STOPWORDS = {\n",
    "    '|', '=', '1', '5', '2018', 'usd', 'price', 'exchange',\n",
    "    'â‚¬', '24', 'utc', 'en', 'high', 'low', 'volume'\n",
    "}\n",
    "BITCOIN_ALIASES = {'btc', 'bit', 'bitcoin', 'bitcoins', 'bit coin'}\n",
    "OTHER_CRYPTO = {\n",
    "    'eth', 'ethereum', 'xrp', 'bch', 'ltc', 'etc', 'ada', 'doge', 'shiba',\n",
    "    'polkadot', 'dot', 'bnb', 'solana', 'trx', 'eos', 'neo', 'iota', 'monero',\n",
    "    'dash', 'zec', 'vechain', 'theta', 'stellar', 'xlm', 'avax', 'algo',\n",
    "    'matic', 'near', 'icp', 'aptos', 'apt', 'kaspa', 'kas'\n",
    "}\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return ''\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    text = INVISIBLE_CHARS.sub('', text)\n",
    "    text = URLS.sub('', text)\n",
    "    text = EMOJIS.sub('', text)\n",
    "    text = text.lower()\n",
    "    text = text.translate(REMOVE_PUNCT_DIGITS)\n",
    "    tokens = text.split()\n",
    "\n",
    "    has_bitcoin = False\n",
    "    clean_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in OTHER_CRYPTO or token in CUSTOM_STOPWORDS:\n",
    "            continue\n",
    "      \n",
    "        if token in BITCOIN_ALIASES:\n",
    "            if has_bitcoin:\n",
    "                continue \n",
    "            else:\n",
    "                clean_tokens.append('bitcoin')\n",
    "                has_bitcoin = True\n",
    "        else:\n",
    "            clean_tokens.append(token)\n",
    "\n",
    "    return ' '.join(clean_tokens)\n",
    "\n",
    "def tokenize(text):\n",
    "    clean_tokens = []\n",
    "    for token in text_to_nlp(text):\n",
    "        if (not token.is_stop) and (token.lemma_ != '-PRON-') and (not token.is_punct):\n",
    "            clean_tokens.append(token.lemma_)\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SP2 = pd.read_csv(\"./Raw/SP500Price.csv\")\n",
    "df_BP2 = pd.read_csv(\"./Raw/BitcoinPrice.csv\")\n",
    "\n",
    "df_BP2.drop(columns=['Vol.','Change %'], inplace=True)\n",
    "\n",
    "df_SP2 = df_SP2.rename(columns={\n",
    "    'Open': 'Open_S',\n",
    "    'Close/Last': 'Close_S',\n",
    "    'High': 'High_S',\n",
    "    'Low': 'Low_S',\n",
    "})\n",
    "\n",
    "df_BP2 = df_BP2.rename(columns={\n",
    "    'Price': 'Close_B',\n",
    "    'Open': 'Open_B',\n",
    "    'High': 'High_B',\n",
    "    'Low': 'Low_B',\n",
    "})\n",
    "\n",
    "for col in ['Close_B', 'Open_B', 'High_B', 'Low_B']:\n",
    "    df_BP2[col] = df_BP2[col].str.replace(',', '')\n",
    "    df_BP2[col] = df_BP2[col].astype(float)  \n",
    "\n",
    "df_SP2['Date'] = pd.to_datetime(df_SP2['Date'])\n",
    "df_BP2['Date'] = pd.to_datetime(df_BP2['Date'])\n",
    "\n",
    "merged_prices = pd.merge(df_SP2, df_BP2, on='Date')\n",
    "merged_prices = merged_prices.sort_values('Date')\n",
    "merged_prices = merged_prices[merged_prices['Date'] <= '2023-06-22']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitcoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BS = pd.read_csv(\"./Raw/BitcoinSent.csv\")\n",
    "\n",
    "df_BS['date'] = pd.to_datetime(df_BS['date'], errors='coerce')\n",
    "df_BS = df_BS[df_BS['date'].notna()]\n",
    "df_BS = df_BS[df_BS['text'].notna()]\n",
    "df_BS = df_BS[df_BS['text'].apply(lambda x: isinstance(x, str))]\n",
    "df_BS = df_BS[df_BS['sentiment_label'].notna()]\n",
    "df_BS = df_BS[df_BS['sentiment_label'].isin(['Positive', 'Negative', 'Neutral'])]\n",
    "df_BS['sentiment_label'] = df_BS['sentiment_label'].map({'Positive': 1,'Neutral' : 0.5 , 'Negative': 0})\n",
    "\n",
    "df_BS = df_BS.sort_values(by='date', ascending=True)\n",
    "avg_sent = df_BS.groupby(df_BS['date'].dt.date)['sentiment_label'].mean().reset_index()\n",
    "\n",
    "avg_sent = avg_sent.rename(columns={'date': 'Date'})\n",
    "avg_sent['Date'] = pd.to_datetime(avg_sent['Date'])\n",
    "\n",
    "\n",
    "prices_sent = pd.merge(merged_prices, avg_sent, on='Date', how='left')\n",
    "file_path = os.path.join('./Processed', 'combined_prices.csv')\n",
    "\n",
    "prices_sent.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#FOR VISUALIZATION - OTHER FILE\\n\\nvisu_words = df_BS\\nvisu_words = visu_words.reset_index(drop=True)\\n\\nvisu_words = visu_words.groupby('date').apply(lambda x: x.sample(n=min(len(x), 3))).reset_index(drop=True)\\n\\nvisu_words['text'] = visu_words['text'].apply(clean_text)\\nvisu_words['text'] = visu_words['text'].apply(tokenize)\\n\\nvisu_words.tail\\nvisu_words.to_pickle('visu_words.pkl')\\n\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "#FOR VISUALIZATION - OTHER FILE\n",
    "\n",
    "visu_words = df_BS\n",
    "visu_words = visu_words.reset_index(drop=True)\n",
    "\n",
    "visu_words = visu_words.groupby('date').apply(lambda x: x.sample(n=min(len(x), 3))).reset_index(drop=True)\n",
    "\n",
    "visu_words['text'] = visu_words['text'].apply(clean_text)\n",
    "visu_words['text'] = visu_words['text'].apply(tokenize)\n",
    "\n",
    "visu_words.tail\n",
    "visu_words.to_pickle('visu_words.pkl')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_BS = df_BS.groupby('date').apply(lambda x: x.sample(n=min(len(x), 5))).reset_index(drop=True)\n",
    "\n",
    "sampled_BS['text'] = sampled_BS['text'].apply(clean_text)\n",
    "\n",
    "sampled_BS['text'] = sampled_BS['text'].apply(tokenize)\n",
    "\n",
    "test = sampled_BS\n",
    "test['body_str'] = test['text'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "test = test.groupby('date').agg({\n",
    "    'text': list,\n",
    "    'body_str': lambda texts: ' '.join(texts),\n",
    "    'sentiment_label': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "file_path = os.path.join('./Processed', 'btc_nlp_test.csv')\n",
    "test.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
